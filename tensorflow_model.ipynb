{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd1e38a-90bd-45ea-9451-be526e8ce768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly import express as px\n",
    "import plotly.graph_objs as go\n",
    "# ML libraries - idk which one to use yet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, mean_absolute_error, r2_score\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing, tree\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial import cKDTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedc2883-6e80-41c9-aec4-5f6d35eb4648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NASA API\n",
    "def get_nasa_power_data(lat, lon, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetches NASA POWER API data for given latitude, longitude, and time range.\n",
    "\n",
    "    Args:\n",
    "    - lat (float): Latitude of the location.\n",
    "    - lon (float): Longitude of the location.\n",
    "    - start_date (str): Start date in YYYYMMDD format.\n",
    "    - end_date (str): End date in YYYYMMDD format.\n",
    "\n",
    "    Returns:\n",
    "    - Pandas DataFrame with selected weather parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Specify multiple parameters in the API request\n",
    "    parameters = \"PRECSNO,T2MDEW,PRECTOTCORR,T2M,WS2M\"\n",
    "\n",
    "    url = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "    params = {\n",
    "        \"parameters\": parameters,\n",
    "        \"community\": \"RE\",\n",
    "        \"longitude\": lon,\n",
    "        \"latitude\": lat,\n",
    "        \"start\": start_date,\n",
    "        \"end\": end_date,\n",
    "        \"format\": \"JSON\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    # Convert JSON response to DataFrame and transpose it\n",
    "    nasa_weather = pd.DataFrame.from_dict(data[\"properties\"][\"parameter\"], orient=\"index\").T\n",
    "\n",
    "    # Reset index and rename date column\n",
    "    nasa_weather.reset_index(inplace=True)\n",
    "    nasa_weather.rename(columns={\"index\": \"date\"}, inplace=True)\n",
    "\n",
    "    # Convert date column to proper datetime format\n",
    "    nasa_weather[\"date\"] = pd.to_datetime(nasa_weather[\"date\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "    nasa_weather.dropna(subset=[\"date\"], inplace=True)  # Remove invalid date rows\n",
    "\n",
    "    nasa_weather.rename(columns={\n",
    "        \"PRECSNO\": \"Snow_Precipitation\",\n",
    "        \"T2MDEW\": \"Dew_Point_2m\",\n",
    "        \"PRECTOTCORR\": \"Total_Precipitation_mm\",\n",
    "        \"T2M\": \"Temperature_2m_C\",\n",
    "        \"WS2M\": \"Wind_Speed_2m\"\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Add Rounded_Lat and Rounded_Lng for merging\n",
    "    nasa_weather['Rounded_Lat'] = lat\n",
    "    nasa_weather['Rounded_Lng'] = lon\n",
    "    \n",
    "    # Display DataFrame\n",
    "    print(f\"\\n Weather Data for Latitude {lat}, Longitude {lon}\\n\")\n",
    "    print(f\"\\n Weather Data for Latitude {lat}, Longitude {lon}\\n\")\n",
    "    nasa_weather['Precipitation(in)'] = nasa_weather['Total_Precipitation_mm'] / 25.4 # mm to in\n",
    "    nasa_weather['Temperature(F)'] = (nasa_weather['Temperature_2m_C'] * (9./5.)) + 32. # C to F\n",
    "    nasa_weather['Wind_Speed(mph)'] = nasa_weather['Wind_Speed_2m'] * 2.237 # m/s to mph\n",
    "    # nasa_weather.dropna()\n",
    "    display(nasa_weather)  # Works in Jupyter Notebook\n",
    "\n",
    "    return nasa_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9938d54-cead-4cf2-a65f-b238d91be651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Weather Data for Latitude 34.05, Longitude -118.25\n",
      "\n",
      "\n",
      " Weather Data for Latitude 34.05, Longitude -118.25\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Snow_Precipitation</th>\n",
       "      <th>Dew_Point_2m</th>\n",
       "      <th>Total_Precipitation_mm</th>\n",
       "      <th>Temperature_2m_C</th>\n",
       "      <th>Wind_Speed_2m</th>\n",
       "      <th>Rounded_Lat</th>\n",
       "      <th>Rounded_Lng</th>\n",
       "      <th>Precipitation(in)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "      <th>Wind_Speed(mph)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>12.14</td>\n",
       "      <td>1.64</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>53.852</td>\n",
       "      <td>3.66868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>11.55</td>\n",
       "      <td>1.59</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>52.790</td>\n",
       "      <td>3.55683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.75</td>\n",
       "      <td>5.87</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.25</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.231102</td>\n",
       "      <td>51.548</td>\n",
       "      <td>7.27025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>9.76</td>\n",
       "      <td>2.89</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>49.568</td>\n",
       "      <td>6.46493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.80</td>\n",
       "      <td>2.00</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.440</td>\n",
       "      <td>4.47400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.12</td>\n",
       "      <td>10.50</td>\n",
       "      <td>2.86</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>50.900</td>\n",
       "      <td>6.39782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7.77</td>\n",
       "      <td>5.29</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.010236</td>\n",
       "      <td>45.986</td>\n",
       "      <td>11.83373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Snow_Precipitation  Dew_Point_2m  Total_Precipitation_mm  \\\n",
       "0 2024-01-01                 0.0          6.12                    0.04   \n",
       "1 2024-01-02                 0.0          7.05                    0.09   \n",
       "2 2024-01-03                 0.0          6.75                    5.87   \n",
       "3 2024-01-04                 0.0          2.14                    0.02   \n",
       "4 2024-01-05                 0.0          1.99                    0.00   \n",
       "5 2024-01-06                 0.0          1.23                    0.12   \n",
       "6 2024-01-07                 0.0         -0.09                    0.26   \n",
       "\n",
       "   Temperature_2m_C  Wind_Speed_2m  Rounded_Lat  Rounded_Lng  \\\n",
       "0             12.14           1.64        34.05      -118.25   \n",
       "1             11.55           1.59        34.05      -118.25   \n",
       "2             10.86           3.25        34.05      -118.25   \n",
       "3              9.76           2.89        34.05      -118.25   \n",
       "4             10.80           2.00        34.05      -118.25   \n",
       "5             10.50           2.86        34.05      -118.25   \n",
       "6              7.77           5.29        34.05      -118.25   \n",
       "\n",
       "   Precipitation(in)  Temperature(F)  Wind_Speed(mph)  \n",
       "0           0.001575          53.852          3.66868  \n",
       "1           0.003543          52.790          3.55683  \n",
       "2           0.231102          51.548          7.27025  \n",
       "3           0.000787          49.568          6.46493  \n",
       "4           0.000000          51.440          4.47400  \n",
       "5           0.004724          50.900          6.39782  \n",
       "6           0.010236          45.986         11.83373  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example: Fetch data for different locations\n",
    "df_la = get_nasa_power_data(34.05, -118.25, \"20240101\", \"20240107\")  # Los Angeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efa465c-3a70-4b5f-bf78-ccc26b0b5fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inspect us_accident data\n",
    "us_accidents = pd.read_csv('US_Accidents_March23.csv')\n",
    "us_accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e57d6c3-abd1-4744-a871-1e401bf3aee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list of all columns in US Accident Data\n",
    "drop_cols = ['ID',\n",
    "            'Source',\n",
    "            # 'Severity', # Severity = target column, 1-4, where 1 indicates the least impact on traffic\n",
    "            'Start_Time',\n",
    "            'End_Time',\n",
    "            'Start_Lat',  \n",
    "            'Start_Lng', \n",
    "            'End_Lat',\n",
    "            'End_Lng',\n",
    "            'Distance(mi)', # Distance(mi) = target column?, length of road extent affected by accident in miles\n",
    "            'Description', # Description = human description of accident\n",
    "            'Street', \n",
    "            'City', \n",
    "            'County',\n",
    "            'State',\n",
    "            'Zipcode',\n",
    "            'Country',\n",
    "            'Timezone',\n",
    "            'Airport_Code',\n",
    "            'Weather_Timestamp', # Weather_Timestamp = shows time-stamp of weather observation record (in local time)\n",
    "            # 'Temperature(F)',\n",
    "            'Wind_Chill(F)',\n",
    "            'Humidity(%)',\n",
    "            'Pressure(in)',\n",
    "            'Visibility(mi)',\n",
    "            'Wind_Direction',\n",
    "            # 'Wind_Speed(mph)',\n",
    "            # 'Precipitation(in)',\n",
    "            'Weather_Condition',\n",
    "            'Amenity',\n",
    "            'Bump',\n",
    "            'Crossing',\n",
    "            'Give_Way',\n",
    "            'Junction',\n",
    "            'No_Exit',\n",
    "            'Railway',\n",
    "            'Roundabout',\n",
    "            'Station',\n",
    "            'Stop',\n",
    "            'Traffic_Calming',\n",
    "            'Traffic_Signal',\n",
    "            'Turning_Loop',\n",
    "            'Sunrise_Sunset', # day or night based on sunrise/sunset\n",
    "            'Civil_Twilight', # day or night based on civil twilight\n",
    "            'Nautical_Twilight', # day or night based on nautical twilight\n",
    "            'Astronomical_Twilight'] # day or night based on astronomical twilight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d4b6a1-e2da-40a3-939c-10d46e3eca18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# string feature that if kept will need to be encoded for ML\n",
    "str_features = 'Weather_Condition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392196e6-5ad4-4765-987d-ff54fe162e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, split, predictors=[], target=[]):\n",
    "    \"\"\"\n",
    "    Prepares the US Accidents DataFrame for merging with NASA weather data, keeping only necessary columns.\n",
    "    \n",
    "    Args:\n",
    "    - df (DataFrame): Raw US Accidents dataset.\n",
    "    - split (boolean): if true, split df by target and predictor data\n",
    "    - ml_drop (list): other columns to drop for machine learning model (adjustable if we decide a variable is not good at predicting)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Processed DataFrame with 'date', 'Rounded_Lat', 'Rounded_Lng', and 'Severity' columns.\n",
    "    \"\"\"\n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Convert time columns to datetime format\n",
    "    df['Start_Time'] = pd.to_datetime(df['Start_Time'], errors='coerce')\n",
    "\n",
    "    # Remove rows with invalid 'Start_Time' values\n",
    "    df = df[df['Start_Time'].notnull()].copy()\n",
    "\n",
    "    # Extract 'date' from 'Start_Time' for merging with NASA weather data\n",
    "    # df['date'] = df['Start_Time'].dt.date\n",
    "\n",
    "    # Filter for coordinates within LA County\n",
    "    df = df[(df['Start_Lat'].between(33.7, 34.8)) & (df['Start_Lng'].between(-119.0, -117.6))]\n",
    "\n",
    "    # Round latitude and longitude to 2 decimal places for approximate matching\n",
    "    df['Rounded_Lat'] = df['Start_Lat'].round(2)\n",
    "    df['Rounded_Lng'] = df['Start_Lng'].round(2)\n",
    "    \n",
    "    # encode str_features\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df['Weather_Condition'] = le.fit_transform(df['Weather_Condition'])\n",
    "    \n",
    "#     # add new columns for increased risk with associated conditions and time\n",
    "#     # for now will start by increased risk with associated weather and time\n",
    "#     df['hour'] = df['Start_Time'].astype(str).str.split(' ').str.get(1).str.split(':').str.get(0)\n",
    "    \n",
    "#     # INCREASED SEVERITY RISK BASED ON LOCATION AND TIME  --------------------------------------------------------------------------\n",
    "    \n",
    "#     # add col to represent frequency of accidents at this location and time\n",
    "#     df['lt_frequency'] = df.groupby(['Rounded_Lat','Rounded_Lng','hour'])['Severity'].transform('count')\n",
    "\n",
    "#     # add col to represent frequency rank of accidents at this location and time compared to rest of location and times\n",
    "#     # rank 0 = lowest frequency rank\n",
    "#     df['lt_frequency_rank'] = df.groupby(['Rounded_Lat','Rounded_Lng','hour'])['lt_frequency'].rank()\n",
    "\n",
    "#     # add col to represent severity rank of accidents at this location and time compared to rest of location and times\n",
    "#     # rank 0 = lowest frequency rank\n",
    "#     df['lt_severity_rank'] = df.groupby(['Rounded_Lat','Rounded_Lng','hour'])['Severity'].rank()\n",
    "    \n",
    "#     # INCREASED SEVERITY RISK BASED ON LOCATION AND WEATHER  --------------------------------------------------------------------------\n",
    "    \n",
    "#     # add col to represent frequency of accidents at this location and time\n",
    "#     df['lw_frequency'] = df.groupby(['Rounded_Lat','Rounded_Lng','Temperature(F)','Wind_Speed(mph)','Precipitation(in)'])['Severity'].transform('count')\n",
    "\n",
    "#     # add col to represent frequency rank of accidents at this location and time compared to rest of location and times\n",
    "#     # rank 0 = lowest frequency rank\n",
    "#     df['lw_frequency_rank'] = df.groupby(['Rounded_Lat','Rounded_Lng','Temperature(F)','Wind_Speed(mph)','Precipitation(in)'])['lw_frequency'].rank()\n",
    "\n",
    "#     # add col to represent severity rank of accidents at this location and time compared to rest of location and times\n",
    "#     # rank 0 = lowest frequency rank\n",
    "#     df['lw_severity_rank'] = df.groupby(['Rounded_Lat','Rounded_Lng','Temperature(F)','Wind_Speed(mph)','Precipitation(in)'])['Severity'].rank()\n",
    "    \n",
    "#     # Compute Risk Changes-----------------------------------------------------------------------------------\n",
    "    \n",
    "#     # Average accident frequency per hour (time baseline)\n",
    "#     avg_hourly_accidents = df.groupby('hour')['lt_frequency'].transform('mean')\n",
    "#     df['time_risk_change'] = (df['lt_frequency'] - avg_hourly_accidents) / avg_hourly_accidents\n",
    "\n",
    "#     # Average accident frequency per weather condition (weather baseline)\n",
    "#     avg_weather_accidents = df.groupby('Weather_Condition')['lt_frequency'].transform('mean')\n",
    "#     df['weather_risk_change'] = (df['lt_frequency'] - avg_weather_accidents) / avg_weather_accidents\n",
    "\n",
    "#     # Combined risk factor (balancing time & weather risks)\n",
    "#     df['combined_risk'] = 0.5 * df['time_risk_change'] + 0.5 * df['weather_risk_change']\n",
    "\n",
    "    # drop NaN\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Keep only relevant columns\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    \n",
    "    # for machine learning clean and prep\n",
    "    if split:\n",
    "        X=df[predictors]\n",
    "        y=df[target]\n",
    "        return X,y\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ac616-80dc-47e6-9ce0-a2a034f4a20d",
   "metadata": {},
   "source": [
    "Trying new neural network based off of https://www.kaggle.com/code/kelixirr/us-accidents-severity-prediction-end-to-end#Preparing-Our-Data-For-The-Model\n",
    "\n",
    "(i had to download tensorflow)\n",
    "\n",
    "prepare_data was changed to only have locaiton and 3 weather attributes (the same that can be obtained from nasa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb724f-e070-4860-bdaf-6335a67f8e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340995de-b9a6-414b-8319-a6bde99439eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if you get ValueError: The least populated class in y has only 1 member, \n",
    "# which is too few. The minimum number of groups for any class cannot be less than 2.\n",
    "# just re-run until it works (idk why)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(us_accidents, test_size=0.2)\n",
    "df_train = prepare_data(train, split=False)\n",
    "# predictors: ['Rounded_Lat','Rounded_Lng','Temperature(F)','Wind_Speed(mph)','Precipitation(in)']\n",
    "X = df_train.drop(columns=['Severity']) \n",
    "# predicting severity of an accident at this location with current weather conditions\n",
    "y = df_train['Severity'] \n",
    "\n",
    "# make training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=30, stratify=y)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.4, random_state=30, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ab8be1-b726-49ec-9328-b0ce4b852276",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# inspect predictors\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e3562d-f107-48d4-a947-1b77b71c0b28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check y_values (severity labels) are in range [0,4] not negative or other\n",
    "y_values = y_test.unique()\n",
    "print(y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30cc853-58ba-41d5-ae18-26183bb8d99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train = y_train - 1\n",
    "y_valid = y_valid - 1  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid_scaled, y_valid))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "valid_dataset = valid_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a103f7-083c-4938-94ac-6199cd3efbf3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_values = train['Severity'].unique()\n",
    "print(unique_values) # 4 unique class for accident severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e07f95-c70e-4a76-b39f-fe7a11969abf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape = (X_train_scaled.shape[1],)))\n",
    "model.add(Dense(256, activation='relu')) \n",
    "model.add(BatchNormalization()) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(4, activation='softmax'))  # 4 unique classes for accident severity\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad20bf72-7930-4655-8f42-837d29a883da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    initial_lr = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10\n",
    "    lr = initial_lr * (drop ** np.floor((1+epoch)/epochs_drop))\n",
    "    return lr\n",
    "\n",
    "# create checkpoint to save best model during training\n",
    "checkpoint_path = 'best_model.keras'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=50,\n",
    "                    validation_data=valid_dataset,\n",
    "                    callbacks=[checkpoint, early_stopping, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f493a75-abe7-40ff-82ec-a1847ec20e26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.path.isfile('best_model.keras') # make sure true before loading saved models in later cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846333cf-e4b0-48a4-91ab-57611902f486",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "saved_model = tf.keras.models.load_model(\"best_model.keras\")\n",
    "val_loss, val_accuracy = saved_model.evaluate(valid_dataset) \n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3908791-e760-44e6-a469-b394bf096eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test = y_test - 1\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_scaled, y_test)) \n",
    "test_dataset = test_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe44a4b-1b5d-476a-bc51-8baba132315d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = saved_model.evaluate(test_dataset) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf60dd1f-464d-4af4-88e3-759cdaf55b40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "y_pred = np.argmax(saved_model.predict(X_test_scaled), axis=1) \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138cf24b-9fa7-4caa-9e3e-a0186d025370",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test = get_nasa_power_data(34.05, -118.25, \"20240101\", \"20240107\")\n",
    "df = df_test[['Rounded_Lat','Rounded_Lng','Temperature(F)','Wind_Speed(mph)','Precipitation(in)']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46afe86-b4b0-4fbd-9f1d-578e028ed73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nasa_test = scaler.transform(df)\n",
    "saved_model.predict(nasa_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721583eb-9de1-47d8-9a0e-dc0623da1816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PIC16B-25W] *",
   "language": "python",
   "name": "conda-env-PIC16B-25W-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
