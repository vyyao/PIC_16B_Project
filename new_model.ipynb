{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd1e38a-90bd-45ea-9451-be526e8ce768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly import express as px\n",
    "import plotly.graph_objs as go\n",
    "# ML libraries - idk which one to use yet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing, tree\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d92a59d-4641-42da-b466-fd1c2c11ad8b",
   "metadata": {},
   "source": [
    "**where i left off (hailey)**\n",
    "- TA said to use supervised neural network instead of linear regression so I chose MLPRegressor but its lowkey ass (see below)\n",
    "- I was thinking predicting relative risk at location/hour/weather would be ideal but idk bc the model isn't looking too hot (this would also require requesting hourly nasa data which i didn't fix get_nasa_power_data to change date to hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedc2883-6e80-41c9-aec4-5f6d35eb4648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NASA API\n",
    "def get_nasa_power_data(lat, lon, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetches NASA POWER API data for given latitude, longitude, and time range.\n",
    "\n",
    "    Args:\n",
    "    - lat (float): Latitude of the location.\n",
    "    - lon (float): Longitude of the location.\n",
    "    - start_date (str): Start date in YYYYMMDD format.\n",
    "    - end_date (str): End date in YYYYMMDD format.\n",
    "\n",
    "    Returns:\n",
    "    - Pandas DataFrame with selected weather parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Specify multiple parameters in the API request\n",
    "    parameters = \"PRECSNO,T2MDEW,PRECTOTCORR,T2M,WS2M\"\n",
    "\n",
    "    url = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "    params = {\n",
    "        \"parameters\": parameters,\n",
    "        \"community\": \"RE\",\n",
    "        \"longitude\": lon,\n",
    "        \"latitude\": lat,\n",
    "        \"start\": start_date,\n",
    "        \"end\": end_date,\n",
    "        \"format\": \"JSON\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    # Convert JSON response to DataFrame and transpose it\n",
    "    nasa_weather = pd.DataFrame.from_dict(data[\"properties\"][\"parameter\"], orient=\"index\").T\n",
    "\n",
    "    # Reset index and rename date column\n",
    "    nasa_weather.reset_index(inplace=True)\n",
    "    nasa_weather.rename(columns={\"index\": \"date\"}, inplace=True)\n",
    "\n",
    "    # Convert date column to proper datetime format\n",
    "    nasa_weather[\"date\"] = pd.to_datetime(nasa_weather[\"date\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "    nasa_weather.dropna(subset=[\"date\"], inplace=True)  # Remove invalid date rows\n",
    "\n",
    "    nasa_weather.rename(columns={\n",
    "        \"PRECSNO\": \"Snow_Precipitation\",\n",
    "        \"T2MDEW\": \"Dew_Point_2m\",\n",
    "        \"PRECTOTCORR\": \"Total_Precipitation_mm\",\n",
    "        \"T2M\": \"Temperature_2m_C\",\n",
    "        \"WS2M\": \"Wind_Speed_2m\"\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Add Rounded_Lat and Rounded_Lng for merging\n",
    "    nasa_weather['Rounded_Lat'] = lat\n",
    "    nasa_weather['Rounded_Lng'] = lon\n",
    "    \n",
    "    # Display DataFrame\n",
    "    print(f\"\\n Weather Data for Latitude {lat}, Longitude {lon}\\n\")\n",
    "    print(f\"\\n Weather Data for Latitude {lat}, Longitude {lon}\\n\")\n",
    "    nasa_weather['Precipitation(in)'] = nasa_weather['Total_Precipitation_mm'] / 25.4 # mm to in\n",
    "    nasa_weather['Temperature(F)'] = (nasa_weather['Temperature_2m_C'] * (9./5.)) + 32. # C to F\n",
    "    nasa_weather['Wind_Speed(mph)'] = nasa_weather['Wind_Speed_2m'] * 2.237 # m/s to mph\n",
    "    # nasa_weather.dropna()\n",
    "    display(nasa_weather)  # Works in Jupyter Notebook\n",
    "\n",
    "    return nasa_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9938d54-cead-4cf2-a65f-b238d91be651",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Weather Data for Latitude 34.05, Longitude -118.25\n",
      "\n",
      "\n",
      " Weather Data for Latitude 34.05, Longitude -118.25\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Snow_Precipitation</th>\n",
       "      <th>Dew_Point_2m</th>\n",
       "      <th>Total_Precipitation_mm</th>\n",
       "      <th>Temperature_2m_C</th>\n",
       "      <th>Wind_Speed_2m</th>\n",
       "      <th>Rounded_Lat</th>\n",
       "      <th>Rounded_Lng</th>\n",
       "      <th>Precipitation(in)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "      <th>Wind_Speed(mph)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>12.14</td>\n",
       "      <td>1.64</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>53.852</td>\n",
       "      <td>3.66868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>11.55</td>\n",
       "      <td>1.59</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>52.790</td>\n",
       "      <td>3.55683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.75</td>\n",
       "      <td>5.87</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.25</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.231102</td>\n",
       "      <td>51.548</td>\n",
       "      <td>7.27025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>9.76</td>\n",
       "      <td>2.89</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>49.568</td>\n",
       "      <td>6.46493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.80</td>\n",
       "      <td>2.00</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.440</td>\n",
       "      <td>4.47400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.12</td>\n",
       "      <td>10.50</td>\n",
       "      <td>2.86</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>50.900</td>\n",
       "      <td>6.39782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7.77</td>\n",
       "      <td>5.29</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.010236</td>\n",
       "      <td>45.986</td>\n",
       "      <td>11.83373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Snow_Precipitation  Dew_Point_2m  Total_Precipitation_mm  \\\n",
       "0 2024-01-01                 0.0          6.12                    0.04   \n",
       "1 2024-01-02                 0.0          7.05                    0.09   \n",
       "2 2024-01-03                 0.0          6.75                    5.87   \n",
       "3 2024-01-04                 0.0          2.14                    0.02   \n",
       "4 2024-01-05                 0.0          1.99                    0.00   \n",
       "5 2024-01-06                 0.0          1.23                    0.12   \n",
       "6 2024-01-07                 0.0         -0.09                    0.26   \n",
       "\n",
       "   Temperature_2m_C  Wind_Speed_2m  Rounded_Lat  Rounded_Lng  \\\n",
       "0             12.14           1.64        34.05      -118.25   \n",
       "1             11.55           1.59        34.05      -118.25   \n",
       "2             10.86           3.25        34.05      -118.25   \n",
       "3              9.76           2.89        34.05      -118.25   \n",
       "4             10.80           2.00        34.05      -118.25   \n",
       "5             10.50           2.86        34.05      -118.25   \n",
       "6              7.77           5.29        34.05      -118.25   \n",
       "\n",
       "   Precipitation(in)  Temperature(F)  Wind_Speed(mph)  \n",
       "0           0.001575          53.852          3.66868  \n",
       "1           0.003543          52.790          3.55683  \n",
       "2           0.231102          51.548          7.27025  \n",
       "3           0.000787          49.568          6.46493  \n",
       "4           0.000000          51.440          4.47400  \n",
       "5           0.004724          50.900          6.39782  \n",
       "6           0.010236          45.986         11.83373  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example: Fetch data for different locations\n",
    "df_la = get_nasa_power_data(34.05, -118.25, \"20240101\", \"20240107\")  # Los Angeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9efa465c-3a70-4b5f-bf78-ccc26b0b5fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>...</th>\n",
       "      <th>Roundabout</th>\n",
       "      <th>Station</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 05:46:00</td>\n",
       "      <td>2016-02-08 11:00:00</td>\n",
       "      <td>39.865147</td>\n",
       "      <td>-84.058723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-2</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:07:59</td>\n",
       "      <td>2016-02-08 06:37:59</td>\n",
       "      <td>39.928059</td>\n",
       "      <td>-82.831184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-3</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:49:27</td>\n",
       "      <td>2016-02-08 07:19:27</td>\n",
       "      <td>39.063148</td>\n",
       "      <td>-84.032608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-4</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 07:23:34</td>\n",
       "      <td>2016-02-08 07:53:34</td>\n",
       "      <td>39.747753</td>\n",
       "      <td>-84.205582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-5</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 07:39:07</td>\n",
       "      <td>2016-02-08 08:09:07</td>\n",
       "      <td>39.627781</td>\n",
       "      <td>-84.188354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID   Source  Severity           Start_Time             End_Time  \\\n",
       "0  A-1  Source2         3  2016-02-08 05:46:00  2016-02-08 11:00:00   \n",
       "1  A-2  Source2         2  2016-02-08 06:07:59  2016-02-08 06:37:59   \n",
       "2  A-3  Source2         2  2016-02-08 06:49:27  2016-02-08 07:19:27   \n",
       "3  A-4  Source2         3  2016-02-08 07:23:34  2016-02-08 07:53:34   \n",
       "4  A-5  Source2         2  2016-02-08 07:39:07  2016-02-08 08:09:07   \n",
       "\n",
       "   Start_Lat  Start_Lng  End_Lat  End_Lng  Distance(mi)  ... Roundabout  \\\n",
       "0  39.865147 -84.058723      NaN      NaN          0.01  ...      False   \n",
       "1  39.928059 -82.831184      NaN      NaN          0.01  ...      False   \n",
       "2  39.063148 -84.032608      NaN      NaN          0.01  ...      False   \n",
       "3  39.747753 -84.205582      NaN      NaN          0.01  ...      False   \n",
       "4  39.627781 -84.188354      NaN      NaN          0.01  ...      False   \n",
       "\n",
       "  Station   Stop Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset  \\\n",
       "0   False  False           False          False        False          Night   \n",
       "1   False  False           False          False        False          Night   \n",
       "2   False  False           False           True        False          Night   \n",
       "3   False  False           False          False        False          Night   \n",
       "4   False  False           False           True        False            Day   \n",
       "\n",
       "  Civil_Twilight Nautical_Twilight Astronomical_Twilight  \n",
       "0          Night             Night                 Night  \n",
       "1          Night             Night                   Day  \n",
       "2          Night               Day                   Day  \n",
       "3            Day               Day                   Day  \n",
       "4            Day               Day                   Day  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect us_accident data\n",
    "us_accidents = pd.read_csv('US_Accidents_March23.csv')\n",
    "us_accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a74597-2201-4f2c-9b95-cbba4120d711",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Light Rain' 'Overcast' 'Mostly Cloudy' 'Rain' 'Light Snow' 'Haze'\n",
      " 'Scattered Clouds' 'Partly Cloudy' 'Clear' 'Snow'\n",
      " 'Light Freezing Drizzle' 'Light Drizzle' 'Fog' 'Shallow Fog' 'Heavy Rain'\n",
      " 'Light Freezing Rain' 'Cloudy' 'Drizzle' nan 'Light Rain Showers' 'Mist'\n",
      " 'Smoke' 'Patches of Fog' 'Light Freezing Fog' 'Light Haze'\n",
      " 'Light Thunderstorms and Rain' 'Thunderstorms and Rain' 'Fair'\n",
      " 'Volcanic Ash' 'Blowing Sand' 'Blowing Dust / Windy' 'Widespread Dust'\n",
      " 'Fair / Windy' 'Rain Showers' 'Mostly Cloudy / Windy'\n",
      " 'Light Rain / Windy' 'Hail' 'Heavy Drizzle' 'Showers in the Vicinity'\n",
      " 'Thunderstorm' 'Light Rain Shower' 'Light Rain with Thunder'\n",
      " 'Partly Cloudy / Windy' 'Thunder in the Vicinity' 'T-Storm'\n",
      " 'Heavy Thunderstorms and Rain' 'Thunder' 'Heavy T-Storm' 'Funnel Cloud'\n",
      " 'Heavy T-Storm / Windy' 'Blowing Snow' 'Light Thunderstorms and Snow'\n",
      " 'Heavy Snow' 'Low Drifting Snow' 'Light Ice Pellets' 'Ice Pellets'\n",
      " 'Squalls' 'N/A Precipitation' 'Cloudy / Windy' 'Light Fog' 'Sand'\n",
      " 'Snow Grains' 'Snow Showers' 'Heavy Thunderstorms and Snow'\n",
      " 'Rain / Windy' 'Heavy Rain / Windy' 'Heavy Ice Pellets'\n",
      " 'Light Snow / Windy' 'Heavy Freezing Rain' 'Small Hail'\n",
      " 'Heavy Rain Showers' 'Thunder / Windy' 'Drizzle and Fog'\n",
      " 'T-Storm / Windy' 'Blowing Dust' 'Smoke / Windy' 'Haze / Windy' 'Tornado'\n",
      " 'Light Drizzle / Windy' 'Widespread Dust / Windy' 'Wintry Mix'\n",
      " 'Wintry Mix / Windy' 'Light Snow with Thunder' 'Fog / Windy'\n",
      " 'Snow and Thunder' 'Light Snow Shower' 'Sleet' 'Light Snow and Sleet'\n",
      " 'Snow / Windy' 'Rain Shower' 'Snow and Sleet' 'Light Sleet'\n",
      " 'Heavy Snow / Windy' 'Freezing Drizzle' 'Light Freezing Rain / Windy'\n",
      " 'Thunder / Wintry Mix' 'Blowing Snow / Windy' 'Freezing Rain'\n",
      " 'Light Snow and Sleet / Windy' 'Snow and Sleet / Windy' 'Sleet / Windy'\n",
      " 'Heavy Freezing Rain / Windy' 'Squalls / Windy'\n",
      " 'Light Rain Shower / Windy' 'Snow and Thunder / Windy'\n",
      " 'Light Sleet / Windy' 'Sand / Dust Whirlwinds' 'Mist / Windy'\n",
      " 'Drizzle / Windy' 'Duststorm' 'Sand / Dust Whirls Nearby'\n",
      " 'Thunder and Hail' 'Heavy Sleet' 'Freezing Rain / Windy'\n",
      " 'Light Snow Shower / Windy' 'Partial Fog' 'Thunder / Wintry Mix / Windy'\n",
      " 'Patches of Fog / Windy' 'Rain and Sleet' 'Light Snow Grains'\n",
      " 'Partial Fog / Windy' 'Sand / Dust Whirlwinds / Windy'\n",
      " 'Heavy Snow with Thunder' 'Light Snow Showers' 'Heavy Blowing Snow'\n",
      " 'Light Hail' 'Heavy Smoke' 'Heavy Thunderstorms with Small Hail'\n",
      " 'Light Thunderstorm' 'Heavy Freezing Drizzle' 'Light Blowing Snow'\n",
      " 'Thunderstorms and Snow' 'Dust Whirls' 'Rain Shower / Windy'\n",
      " 'Sleet and Thunder' 'Heavy Sleet and Thunder' 'Drifting Snow / Windy'\n",
      " 'Shallow Fog / Windy' 'Thunder and Hail / Windy' 'Heavy Sleet / Windy'\n",
      " 'Sand / Windy' 'Heavy Rain Shower / Windy' 'Blowing Snow Nearby'\n",
      " 'Heavy Rain Shower' 'Drifting Snow']\n"
     ]
    }
   ],
   "source": [
    "unique_values = us_accidents['Weather_Condition'].unique()\n",
    "\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e57d6c3-abd1-4744-a871-1e401bf3aee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list of all columns in US Accident Data\n",
    "drop_cols = ['ID',\n",
    "            'Source',\n",
    "            # 'Severity', # Severity = target column, 1-4, where 1 indicates the least impact on traffic\n",
    "            'Start_Time',\n",
    "            'End_Time',\n",
    "            'Start_Lat',  \n",
    "            'Start_Lng', \n",
    "            'End_Lat',\n",
    "            'End_Lng',\n",
    "            'Distance(mi)', # Distance(mi) = target column?, length of road extent affected by accident in miles\n",
    "            'Description', # Description = human description of accident\n",
    "            'Street', \n",
    "            'City', \n",
    "            'County',\n",
    "            'State',\n",
    "            'Zipcode',\n",
    "            'Country',\n",
    "            'Timezone',\n",
    "            'Airport_Code',\n",
    "            'Weather_Timestamp', # Weather_Timestamp = shows time-stamp of weather observation record (in local time)\n",
    "            # 'Temperature(F)',\n",
    "            'Wind_Chill(F)',\n",
    "            'Humidity(%)',\n",
    "            'Pressure(in)',\n",
    "            'Visibility(mi)',\n",
    "            'Wind_Direction',\n",
    "            # 'Wind_Speed(mph)',\n",
    "            # 'Precipitation(in)',\n",
    "            # 'Weather_Condition',\n",
    "            'Amenity',\n",
    "            'Bump',\n",
    "            'Crossing',\n",
    "            'Give_Way',\n",
    "            'Junction',\n",
    "            'No_Exit',\n",
    "            'Railway',\n",
    "            'Roundabout',\n",
    "            'Station',\n",
    "            'Stop',\n",
    "            'Traffic_Calming',\n",
    "            'Traffic_Signal',\n",
    "            'Turning_Loop',\n",
    "            'Sunrise_Sunset', # day or night based on sunrise/sunset\n",
    "            'Civil_Twilight', # day or night based on civil twilight\n",
    "            'Nautical_Twilight', # day or night based on nautical twilight\n",
    "            'Astronomical_Twilight'] # day or night based on astronomical twilight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d4b6a1-e2da-40a3-939c-10d46e3eca18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# string feature that if kept will need to be encoded for ML\n",
    "str_features = 'Weather_Condition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "392196e6-5ad4-4765-987d-ff54fe162e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, split, predictors, target):\n",
    "    \"\"\"\n",
    "    Prepares the US Accidents DataFrame for merging with NASA weather data, keeping only necessary columns.\n",
    "    \n",
    "    Args:\n",
    "    - df (DataFrame): Raw US Accidents dataset.\n",
    "    - split (boolean): if true, split df by target and predictor data\n",
    "    - ml_drop (list): other columns to drop for machine learning model (adjustable if we decide a variable is not good at predicting)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Processed DataFrame with 'date', 'Rounded_Lat', 'Rounded_Lng', and 'Severity' columns.\n",
    "    \"\"\"\n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Convert time columns to datetime format\n",
    "    df['Start_Time'] = pd.to_datetime(df['Start_Time'], errors='coerce')\n",
    "\n",
    "    # Remove rows with invalid 'Start_Time' values\n",
    "    df = df[df['Start_Time'].notnull()].copy()\n",
    "\n",
    "    # Extract 'date' from 'Start_Time' for merging with NASA weather data\n",
    "    # df['date'] = df['Start_Time'].dt.date\n",
    "\n",
    "    # Filter for coordinates within LA County\n",
    "    df = df[(df['Start_Lat'].between(33.7, 34.8)) & (df['Start_Lng'].between(-119.0, -117.6))]\n",
    "\n",
    "    # Round latitude and longitude to 2 decimal places for approximate matching\n",
    "    df['Rounded_Lat'] = df['Start_Lat'].round(2)\n",
    "    df['Rounded_Lng'] = df['Start_Lng'].round(2)\n",
    "    \n",
    "    # encode str_features\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df['Weather_Condition'] = le.fit_transform(df['Weather_Condition'])\n",
    "    \n",
    "    # add new columns for increased risk with associated conditions and time\n",
    "    # for now will start by increased risk with associated weather and time\n",
    "    df['hour'] = df['Start_Time'].astype(str).str.split(' ').str.get(1).str.split(':').str.get(0)\n",
    "    \n",
    "    # INCREASED SEVERITY RISK BASED ON LOCATION AND TIME  --------------------------------------------------------------------------\n",
    "    \n",
    "    # add col to represent frequency of accidents at this location and time\n",
    "    df['lt_frequency'] = df.groupby(['Rounded_Lat','Rounded_Lng','hour'])['Severity'].transform('count')\n",
    "\n",
    "    # add col to represent frequency rank of accidents at this location and time compared to rest of location and times\n",
    "    # rank 0 = lowest frequency rank\n",
    "    df['lt_frequency_rank'] = df.groupby(['Rounded_Lat','Rounded_Lng','hour'])['lt_frequency'].rank()\n",
    "\n",
    "    # add col to represent severity rank of accidents at this location and time compared to rest of location and times\n",
    "    # rank 0 = lowest frequency rank\n",
    "    df['lt_severity_rank'] = df.groupby(['Rounded_Lat','Rounded_Lng','hour'])['Severity'].rank()\n",
    "    \n",
    "    # INCREASED SEVERITY RISK BASED ON LOCATION AND WEATHER  --------------------------------------------------------------------------\n",
    "    \n",
    "    # add col to represent frequency of accidents at this location and time\n",
    "    df['lw_frequency'] = df.groupby(['Rounded_Lat','Rounded_Lng','Temperature(F)','Wind_Speed(mph)','Precipitation(in)'])['Severity'].transform('count')\n",
    "\n",
    "    # add col to represent frequency rank of accidents at this location and time compared to rest of location and times\n",
    "    # rank 0 = lowest frequency rank\n",
    "    df['lw_frequency_rank'] = df.groupby(['Rounded_Lat','Rounded_Lng','Temperature(F)','Wind_Speed(mph)','Precipitation(in)'])['lw_frequency'].rank()\n",
    "\n",
    "    # add col to represent severity rank of accidents at this location and time compared to rest of location and times\n",
    "    # rank 0 = lowest frequency rank\n",
    "    df['lw_severity_rank'] = df.groupby(['Rounded_Lat','Rounded_Lng','Temperature(F)','Wind_Speed(mph)','Precipitation(in)'])['Severity'].rank()\n",
    "    \n",
    "    # drop NaN\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Keep only relevant columns\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    \n",
    "    # for machine learning clean and prep\n",
    "    if split:\n",
    "        X=df[predictors]\n",
    "        y=df[target]\n",
    "        return X,y\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e76987-71ca-417e-a022-59014571d039",
   "metadata": {},
   "source": [
    "### MLPRegressor\n",
    "\n",
    "- sklearn documentation https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\n",
    "\n",
    "Things to consider:\n",
    "\n",
    "- lowkey don't know good risk metric\n",
    "- what do we want to predict?\n",
    "- we could have 2 different models that relative accident frequency based off of location and weather and location and time (hour) --> predicts lw_frequency_rank and lt_frequency_rank (i think predicting relative accident frequency is more intuitive than relative accident severity)\n",
    "- we could have 2 different models that relative accident severity based off of location and weather and location and time (hour) --> predicts lw_severity_rank and lt_severity_rank\n",
    "- we could have 4 different models that do both above ^\n",
    "- we could come up with a new metric that combines all and only have one model (i just don't know best way to represent that)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "67570ed0-ae98-46eb-83e0-1fc7fe66b022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(us_accidents, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "63246330-537e-4ec8-8042-3051bc998831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model to predict relative accident frequency based off of location and time\n",
    "X, y = prepare_data(df=train, split=True, predictors=['Rounded_Lat','Rounded_Lng','Temperature(F)','Wind_Speed(mph)','Precipitation(in)'], target='lw_frequency_rank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6f0a9073-c7fb-4564-9529-870686750d85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2420844635178483"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also takes forever\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "lt_regr = MLPRegressor(random_state=1, solver='lbfgs',max_iter=3000, tol=0.02, hidden_layer_sizes=200, alpha=0.005, )\n",
    "lt_regr.fit(X_train, y_train)\n",
    "lt_regr.predict(X_test)\n",
    "lt_regr.score(X_test, y_test) # sad scores :(\n",
    "# increasing max_iter seems to increase the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6b1eda81-ed2d-48a4-b8b5-e7b4e2699155",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[119], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m     12\u001b[0m                 regr\u001b[38;5;241m.\u001b[39mset_params(solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m, max_iter\u001b[38;5;241m=\u001b[39mmi, hidden_layer_sizes\u001b[38;5;241m=\u001b[39mhls, tol\u001b[38;5;241m=\u001b[39mt, alpha\u001b[38;5;241m=\u001b[39ma)\n\u001b[1;32m---> 13\u001b[0m                 scores \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#gets cross validation score\u001b[39;00m\n\u001b[0;32m     15\u001b[0m                 cv_scores\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m\"\u001b[39m:mi,\n\u001b[0;32m     16\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhidden_layer_sizes\u001b[39m\u001b[38;5;124m\"\u001b[39m:hls,\n\u001b[0;32m     17\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtol\u001b[39m\u001b[38;5;124m\"\u001b[39m:t,\n\u001b[0;32m     18\u001b[0m                                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m\"\u001b[39m:a})\n\u001b[0;32m     20\u001b[0m best_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(cv_scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_accuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;66;03m#find the parameters with the highest (best) cv score\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:753\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    736\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m    737\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model to data matrix X and target(s) y.\u001b[39;00m\n\u001b[0;32m    738\u001b[0m \n\u001b[0;32m    739\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;124;03m        Returns a trained MLP model.\u001b[39;00m\n\u001b[0;32m    752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mincremental\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:489\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# Run the LBFGS solver\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msolver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 489\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_lbfgs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeltas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintercept_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_units\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;66;03m# validate parameter weights\u001b[39;00m\n\u001b[0;32m    494\u001b[0m weights \u001b[38;5;241m=\u001b[39m chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoefs_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercepts_)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:533\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._fit_lbfgs\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads, layer_units)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    531\u001b[0m     iprint \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 533\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_loss_grad_lbfgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_coef_inter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    539\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxfun\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_fun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    540\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    541\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    542\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeltas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintercept_grads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m _check_optimize_result(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m\"\u001b[39m, opt_res, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter)\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_ \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:365\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    359\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 365\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    368\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 71\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:282\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._loss_grad_lbfgs\u001b[1;34m(self, packed_coef_inter, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the MLP loss function and its corresponding derivatives\u001b[39;00m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03mwith respect to the different parameters given in the initialization.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;124;03mgrad : array-like, shape (number of nodes of all layers,)\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unpack(packed_coef_inter)\n\u001b[1;32m--> 282\u001b[0m loss, coef_grads, intercept_grads \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backprop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeltas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoef_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintercept_grads\u001b[49m\n\u001b[0;32m    284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    285\u001b[0m grad \u001b[38;5;241m=\u001b[39m _pack(coef_grads, intercept_grads)\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, grad\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:327\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._backprop\u001b[1;34m(self, X, y, activations, deltas, coef_grads, intercept_grads)\u001b[0m\n\u001b[0;32m    324\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    326\u001b[0m \u001b[38;5;66;03m# Forward propagate\u001b[39;00m\n\u001b[1;32m--> 327\u001b[0m activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;66;03m# Get loss\u001b[39;00m\n\u001b[0;32m    330\u001b[0m loss_func_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:179\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass\u001b[1;34m(self, activations)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;66;03m# For the hidden layers\u001b[39;00m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layers_ \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m--> 179\u001b[0m         \u001b[43mhidden_activation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# For the last layer\u001b[39;00m\n\u001b[0;32m    182\u001b[0m output_activation \u001b[38;5;241m=\u001b[39m ACTIVATIONS[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_activation_]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\neural_network\\_base.py:46\u001b[0m, in \u001b[0;36minplace_relu\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the hyperbolic tan function inplace.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m        The input data.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     43\u001b[0m     np\u001b[38;5;241m.\u001b[39mtanh(X, out\u001b[38;5;241m=\u001b[39mX)\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minplace_relu\u001b[39m(X):\n\u001b[0;32m     47\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the rectified linear unit function inplace.\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03m        The input data.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     54\u001b[0m     np\u001b[38;5;241m.\u001b[39mmaximum(X, \u001b[38;5;241m0\u001b[39m, out\u001b[38;5;241m=\u001b[39mX)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# this takes forever maybe don't run it\n",
    "regr = MLPRegressor(random_state=1, solver='lbfgs')\n",
    "parameters = {\"max_iter\": list(range(2000,5000,1000)), \n",
    "              \"hidden_layer_sizes\": list(range(100, 500, 100)),\n",
    "             \"tol\": [0.1,0.2,0.3,0.4,0.5],\n",
    "             \"alpha\": [0.0001, 0.0005, 0.001, 0.005, 0.01],}\n",
    "cv_scores = [] #holds the cross validation scores\n",
    "#try every combination of estimators and max depth, recording them and their scores\n",
    "for mi in parameters['max_iter']:\n",
    "    for hls in parameters['hidden_layer_sizes']:\n",
    "        for t in parameters['tol']:\n",
    "            for a in parameters['alpha']:\n",
    "                regr.set_params(solver='lbfgs', max_iter=mi, hidden_layer_sizes=hls, tol=t, alpha=a)\n",
    "                scores = cross_val_score(regr, X_train, y_train, cv=5) #gets cross validation score\n",
    "                \n",
    "                cv_scores.append({\"max_iter\":mi,\n",
    "                                 \"hidden_layer_sizes\":hls,\n",
    "                                 \"tol\":t,\n",
    "                                 \"alpha\":a})\n",
    "\n",
    "best_params = max(cv_scores, key=lambda x: x[\"mean_accuracy\"]) #find the parameters with the highest (best) cv score\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688a7442-6d82-4fc0-8b0a-ad26ecdc0a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ideally once best parameters are found and target prediction is confirmed we just predict whatever using nasa power data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ca0fd-6876-4c52-8a3c-7e8fd4160bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PIC16B-25W] *",
   "language": "python",
   "name": "conda-env-PIC16B-25W-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
