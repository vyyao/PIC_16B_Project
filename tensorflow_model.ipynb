{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd1e38a-90bd-45ea-9451-be526e8ce768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly import express as px\n",
    "import plotly.graph_objs as go\n",
    "# ML libraries - idk which one to use yet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, mean_absolute_error, r2_score\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from matplotlib.patches import Patch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import preprocessing, tree\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from scipy.spatial import cKDTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fedc2883-6e80-41c9-aec4-5f6d35eb4648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# NASA API\n",
    "def get_nasa_power_data(lat, lon, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetches NASA POWER API data for given latitude, longitude, and time range.\n",
    "\n",
    "    Args:\n",
    "    - lat (float): Latitude of the location.\n",
    "    - lon (float): Longitude of the location.\n",
    "    - start_date (str): Start date in YYYYMMDD format.\n",
    "    - end_date (str): End date in YYYYMMDD format.\n",
    "\n",
    "    Returns:\n",
    "    - Pandas DataFrame with selected weather parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Specify multiple parameters in the API request\n",
    "    parameters = \"PRECSNO,T2MDEW,PRECTOTCORR,T2M,WS2M\"\n",
    "\n",
    "    url = \"https://power.larc.nasa.gov/api/temporal/daily/point\"\n",
    "    params = {\n",
    "        \"parameters\": parameters,\n",
    "        \"community\": \"RE\",\n",
    "        \"longitude\": lon,\n",
    "        \"latitude\": lat,\n",
    "        \"start\": start_date,\n",
    "        \"end\": end_date,\n",
    "        \"format\": \"JSON\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    data = response.json()\n",
    "\n",
    "    # Convert JSON response to DataFrame and transpose it\n",
    "    nasa_weather = pd.DataFrame.from_dict(data[\"properties\"][\"parameter\"], orient=\"index\").T\n",
    "\n",
    "    # Reset index and rename date column\n",
    "    nasa_weather.reset_index(inplace=True)\n",
    "    nasa_weather.rename(columns={\"index\": \"date\"}, inplace=True)\n",
    "\n",
    "    # Convert date column to proper datetime format\n",
    "    nasa_weather[\"date\"] = pd.to_datetime(nasa_weather[\"date\"], format=\"%Y%m%d\", errors=\"coerce\")\n",
    "    nasa_weather.dropna(subset=[\"date\"], inplace=True)  # Remove invalid date rows\n",
    "\n",
    "    nasa_weather.rename(columns={\n",
    "        \"PRECSNO\": \"Snow_Precipitation\",\n",
    "        \"T2MDEW\": \"Dew_Point_2m\",\n",
    "        \"PRECTOTCORR\": \"Total_Precipitation_mm\",\n",
    "        \"T2M\": \"Temperature_2m_C\",\n",
    "        \"WS2M\": \"Wind_Speed_2m\"\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # Add Rounded_Lat and Rounded_Lng for merging\n",
    "    nasa_weather['Rounded_Lat'] = lat\n",
    "    nasa_weather['Rounded_Lng'] = lon\n",
    "    \n",
    "    # Display DataFrame\n",
    "    print(f\"\\n Weather Data for Latitude {lat}, Longitude {lon}\\n\")\n",
    "    print(f\"\\n Weather Data for Latitude {lat}, Longitude {lon}\\n\")\n",
    "    nasa_weather['Precipitation(in)'] = nasa_weather['Total_Precipitation_mm'] / 25.4 # mm to in\n",
    "    nasa_weather['Temperature(F)'] = (nasa_weather['Temperature_2m_C'] * (9./5.)) + 32. # C to F\n",
    "    nasa_weather['Wind_Speed(mph)'] = nasa_weather['Wind_Speed_2m'] * 2.237 # m/s to mph\n",
    "    # nasa_weather.dropna()\n",
    "    display(nasa_weather)  # Works in Jupyter Notebook\n",
    "\n",
    "    return nasa_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9938d54-cead-4cf2-a65f-b238d91be651",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Weather Data for Latitude 34.05, Longitude -118.25\n",
      "\n",
      "\n",
      " Weather Data for Latitude 34.05, Longitude -118.25\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Snow_Precipitation</th>\n",
       "      <th>Dew_Point_2m</th>\n",
       "      <th>Total_Precipitation_mm</th>\n",
       "      <th>Temperature_2m_C</th>\n",
       "      <th>Wind_Speed_2m</th>\n",
       "      <th>Rounded_Lat</th>\n",
       "      <th>Rounded_Lng</th>\n",
       "      <th>Precipitation(in)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "      <th>Wind_Speed(mph)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>12.14</td>\n",
       "      <td>1.64</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>53.852</td>\n",
       "      <td>3.66868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>11.55</td>\n",
       "      <td>1.59</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>52.790</td>\n",
       "      <td>3.55683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.75</td>\n",
       "      <td>5.87</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.25</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.231102</td>\n",
       "      <td>51.548</td>\n",
       "      <td>7.27025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>9.76</td>\n",
       "      <td>2.89</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>49.568</td>\n",
       "      <td>6.46493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.80</td>\n",
       "      <td>2.00</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.440</td>\n",
       "      <td>4.47400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.12</td>\n",
       "      <td>10.50</td>\n",
       "      <td>2.86</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>50.900</td>\n",
       "      <td>6.39782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7.77</td>\n",
       "      <td>5.29</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.010236</td>\n",
       "      <td>45.986</td>\n",
       "      <td>11.83373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Snow_Precipitation  Dew_Point_2m  Total_Precipitation_mm  \\\n",
       "0 2024-01-01                 0.0          6.12                    0.04   \n",
       "1 2024-01-02                 0.0          7.05                    0.09   \n",
       "2 2024-01-03                 0.0          6.75                    5.87   \n",
       "3 2024-01-04                 0.0          2.14                    0.02   \n",
       "4 2024-01-05                 0.0          1.99                    0.00   \n",
       "5 2024-01-06                 0.0          1.23                    0.12   \n",
       "6 2024-01-07                 0.0         -0.09                    0.26   \n",
       "\n",
       "   Temperature_2m_C  Wind_Speed_2m  Rounded_Lat  Rounded_Lng  \\\n",
       "0             12.14           1.64        34.05      -118.25   \n",
       "1             11.55           1.59        34.05      -118.25   \n",
       "2             10.86           3.25        34.05      -118.25   \n",
       "3              9.76           2.89        34.05      -118.25   \n",
       "4             10.80           2.00        34.05      -118.25   \n",
       "5             10.50           2.86        34.05      -118.25   \n",
       "6              7.77           5.29        34.05      -118.25   \n",
       "\n",
       "   Precipitation(in)  Temperature(F)  Wind_Speed(mph)  \n",
       "0           0.001575          53.852          3.66868  \n",
       "1           0.003543          52.790          3.55683  \n",
       "2           0.231102          51.548          7.27025  \n",
       "3           0.000787          49.568          6.46493  \n",
       "4           0.000000          51.440          4.47400  \n",
       "5           0.004724          50.900          6.39782  \n",
       "6           0.010236          45.986         11.83373  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example: Fetch data for different locations\n",
    "df_la = get_nasa_power_data(34.05, -118.25, \"20240101\", \"20240107\")  # Los Angeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9efa465c-3a70-4b5f-bf78-ccc26b0b5fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>...</th>\n",
       "      <th>Roundabout</th>\n",
       "      <th>Station</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 05:46:00</td>\n",
       "      <td>2016-02-08 11:00:00</td>\n",
       "      <td>39.865147</td>\n",
       "      <td>-84.058723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-2</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:07:59</td>\n",
       "      <td>2016-02-08 06:37:59</td>\n",
       "      <td>39.928059</td>\n",
       "      <td>-82.831184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-3</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:49:27</td>\n",
       "      <td>2016-02-08 07:19:27</td>\n",
       "      <td>39.063148</td>\n",
       "      <td>-84.032608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-4</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 07:23:34</td>\n",
       "      <td>2016-02-08 07:53:34</td>\n",
       "      <td>39.747753</td>\n",
       "      <td>-84.205582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-5</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 07:39:07</td>\n",
       "      <td>2016-02-08 08:09:07</td>\n",
       "      <td>39.627781</td>\n",
       "      <td>-84.188354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID   Source  Severity           Start_Time             End_Time  \\\n",
       "0  A-1  Source2         3  2016-02-08 05:46:00  2016-02-08 11:00:00   \n",
       "1  A-2  Source2         2  2016-02-08 06:07:59  2016-02-08 06:37:59   \n",
       "2  A-3  Source2         2  2016-02-08 06:49:27  2016-02-08 07:19:27   \n",
       "3  A-4  Source2         3  2016-02-08 07:23:34  2016-02-08 07:53:34   \n",
       "4  A-5  Source2         2  2016-02-08 07:39:07  2016-02-08 08:09:07   \n",
       "\n",
       "   Start_Lat  Start_Lng  End_Lat  End_Lng  Distance(mi)  ... Roundabout  \\\n",
       "0  39.865147 -84.058723      NaN      NaN          0.01  ...      False   \n",
       "1  39.928059 -82.831184      NaN      NaN          0.01  ...      False   \n",
       "2  39.063148 -84.032608      NaN      NaN          0.01  ...      False   \n",
       "3  39.747753 -84.205582      NaN      NaN          0.01  ...      False   \n",
       "4  39.627781 -84.188354      NaN      NaN          0.01  ...      False   \n",
       "\n",
       "  Station   Stop Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset  \\\n",
       "0   False  False           False          False        False          Night   \n",
       "1   False  False           False          False        False          Night   \n",
       "2   False  False           False           True        False          Night   \n",
       "3   False  False           False          False        False          Night   \n",
       "4   False  False           False           True        False            Day   \n",
       "\n",
       "  Civil_Twilight Nautical_Twilight Astronomical_Twilight  \n",
       "0          Night             Night                 Night  \n",
       "1          Night             Night                   Day  \n",
       "2          Night               Day                   Day  \n",
       "3            Day               Day                   Day  \n",
       "4            Day               Day                   Day  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect us_accident data\n",
    "us_accidents = pd.read_csv('US_Accidents_March23.csv')\n",
    "us_accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e57d6c3-abd1-4744-a871-1e401bf3aee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# list of all columns in US Accident Data\n",
    "drop_cols = ['ID',\n",
    "            'Source',\n",
    "            # 'Severity', # Severity = target column, 1-4, where 1 indicates the least impact on traffic\n",
    "            'Start_Time',\n",
    "            'End_Time',\n",
    "            'Start_Lat',  \n",
    "            'Start_Lng', \n",
    "            'End_Lat',\n",
    "            'End_Lng',\n",
    "            'Distance(mi)', # Distance(mi) = target column?, length of road extent affected by accident in miles\n",
    "            'Description', # Description = human description of accident\n",
    "            'Street', \n",
    "            'City', \n",
    "            'County',\n",
    "            'State',\n",
    "            'Zipcode',\n",
    "            'Country',\n",
    "            'Timezone',\n",
    "            'Airport_Code',\n",
    "            'Weather_Timestamp', # Weather_Timestamp = shows time-stamp of weather observation record (in local time)\n",
    "            # 'Temperature(F)',\n",
    "            'Wind_Chill(F)',\n",
    "            'Humidity(%)',\n",
    "            'Pressure(in)',\n",
    "            'Visibility(mi)',\n",
    "            'Wind_Direction',\n",
    "            # 'Wind_Speed(mph)',\n",
    "            # 'Precipitation(in)',\n",
    "            'Weather_Condition',\n",
    "            'Amenity',\n",
    "            'Bump',\n",
    "            'Crossing',\n",
    "            'Give_Way',\n",
    "            'Junction',\n",
    "            'No_Exit',\n",
    "            'Railway',\n",
    "            'Roundabout',\n",
    "            'Station',\n",
    "            'Stop',\n",
    "            'Traffic_Calming',\n",
    "            'Traffic_Signal',\n",
    "            'Turning_Loop',\n",
    "            'Sunrise_Sunset', # day or night based on sunrise/sunset\n",
    "            'Civil_Twilight', # day or night based on civil twilight\n",
    "            'Nautical_Twilight', # day or night based on nautical twilight\n",
    "            'Astronomical_Twilight'] # day or night based on astronomical twilight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d4b6a1-e2da-40a3-939c-10d46e3eca18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# string feature that if kept will need to be encoded for ML\n",
    "str_features = 'Weather_Condition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "392196e6-5ad4-4765-987d-ff54fe162e49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_data(df, split, predictors=[], target=[]):\n",
    "    \"\"\"\n",
    "    Prepares the US Accidents DataFrame for merging with NASA weather data, keeping only necessary columns.\n",
    "    \n",
    "    Args:\n",
    "    - df (DataFrame): Raw US Accidents dataset.\n",
    "    - split (boolean): if true, split df by target and predictor data\n",
    "    - ml_drop (list): other columns to drop for machine learning model (adjustable if we decide a variable is not good at predicting)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: Processed DataFrame with 'date', 'Rounded_Lat', 'Rounded_Lng', and 'Severity' columns.\n",
    "    \"\"\"\n",
    "    # Drop duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Convert time columns to datetime format\n",
    "    df['Start_Time'] = pd.to_datetime(df['Start_Time'], errors='coerce')\n",
    "\n",
    "    # Remove rows with invalid 'Start_Time' values\n",
    "    df = df[df['Start_Time'].notnull()].copy()\n",
    "\n",
    "    # Extract 'date' from 'Start_Time' for merging with NASA weather data\n",
    "    # df['date'] = df['Start_Time'].dt.date\n",
    "\n",
    "    # Filter for coordinates within LA County\n",
    "    df = df[(df['Start_Lat'].between(33.7, 34.8)) & (df['Start_Lng'].between(-119.0, -117.6))]\n",
    "\n",
    "    # Round latitude and longitude to 2 decimal places for approximate matching\n",
    "    df['Rounded_Lat'] = df['Start_Lat'].round(2)\n",
    "    df['Rounded_Lng'] = df['Start_Lng'].round(2)\n",
    "    \n",
    "    # encode str_features\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df['Weather_Condition'] = le.fit_transform(df['Weather_Condition'])\n",
    "    \n",
    "#     # add new columns for increased risk with associated conditions and time\n",
    "#     # for now will start by increased risk with associated weather and time\n",
    "#     df['hour'] = df['Start_Time'].astype(str).str.split(' ').str.get(1).str.split(':').str.get(0)\n",
    "    \n",
    "#     # INCREASED SEVERITY RISK BASED ON LOCATION AND TIME  --------------------------------------------------------------------------\n",
    "    \n",
    "#     # add col to represent frequency of accidents at this location and time\n",
    "#     df['lt_frequency'] = df.groupby(['Rounded_Lat','Rounded_Lng','hour'])['Severity'].transform('count')\n",
    "\n",
    "#     # add col to represent frequency rank of accidents at this location and time compared to rest of location and times\n",
    "#     # rank 0 = lowest frequency rank\n",
    "#     df['lt_frequency_rank'] = df.groupby(['Rounded_Lat','Rounded_Lng','hour'])['lt_frequency'].rank()\n",
    "\n",
    "#     # add col to represent severity rank of accidents at this location and time compared to rest of location and times\n",
    "#     # rank 0 = lowest frequency rank\n",
    "#     df['lt_severity_rank'] = df.groupby(['Rounded_Lat','Rounded_Lng','hour'])['Severity'].rank()\n",
    "    \n",
    "#     # INCREASED SEVERITY RISK BASED ON LOCATION AND WEATHER  --------------------------------------------------------------------------\n",
    "    \n",
    "#     # add col to represent frequency of accidents at this location and time\n",
    "#     df['lw_frequency'] = df.groupby(['Rounded_Lat','Rounded_Lng','Temperature(F)','Wind_Speed(mph)','Precipitation(in)'])['Severity'].transform('count')\n",
    "\n",
    "#     # add col to represent frequency rank of accidents at this location and time compared to rest of location and times\n",
    "#     # rank 0 = lowest frequency rank\n",
    "#     df['lw_frequency_rank'] = df.groupby(['Rounded_Lat','Rounded_Lng','Temperature(F)','Wind_Speed(mph)','Precipitation(in)'])['lw_frequency'].rank()\n",
    "\n",
    "#     # add col to represent severity rank of accidents at this location and time compared to rest of location and times\n",
    "#     # rank 0 = lowest frequency rank\n",
    "#     df['lw_severity_rank'] = df.groupby(['Rounded_Lat','Rounded_Lng','Temperature(F)','Wind_Speed(mph)','Precipitation(in)'])['Severity'].rank()\n",
    "    \n",
    "#     # Compute Risk Changes-----------------------------------------------------------------------------------\n",
    "    \n",
    "#     # Average accident frequency per hour (time baseline)\n",
    "#     avg_hourly_accidents = df.groupby('hour')['lt_frequency'].transform('mean')\n",
    "#     df['time_risk_change'] = (df['lt_frequency'] - avg_hourly_accidents) / avg_hourly_accidents\n",
    "\n",
    "#     # Average accident frequency per weather condition (weather baseline)\n",
    "#     avg_weather_accidents = df.groupby('Weather_Condition')['lt_frequency'].transform('mean')\n",
    "#     df['weather_risk_change'] = (df['lt_frequency'] - avg_weather_accidents) / avg_weather_accidents\n",
    "\n",
    "#     # Combined risk factor (balancing time & weather risks)\n",
    "#     df['combined_risk'] = 0.5 * df['time_risk_change'] + 0.5 * df['weather_risk_change']\n",
    "\n",
    "    # drop NaN\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # Keep only relevant columns\n",
    "    df = df.drop(drop_cols, axis=1)\n",
    "    \n",
    "    # for machine learning clean and prep\n",
    "    if split:\n",
    "        X=df[predictors]\n",
    "        y=df[target]\n",
    "        return X,y\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9ac616-80dc-47e6-9ce0-a2a034f4a20d",
   "metadata": {},
   "source": [
    "Trying new neural network based off of https://www.kaggle.com/code/kelixirr/us-accidents-severity-prediction-end-to-end#Preparing-Our-Data-For-The-Model\n",
    "\n",
    "(i had to download tensorflow)\n",
    "\n",
    "prepare_data was changed to only have locaiton and 3 weather attributes (the same that can be obtained from nasa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cdb724f-e070-4860-bdaf-6335a67f8e10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "340995de-b9a6-414b-8319-a6bde99439eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if you get ValueError: The least populated class in y has only 1 member, \n",
    "# which is too few. The minimum number of groups for any class cannot be less than 2.\n",
    "# just re-run until it works (idk why)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(us_accidents, test_size=0.2)\n",
    "df_train = prepare_data(train, split=False)\n",
    "# predictors: ['Rounded_Lat','Rounded_Lng','Temperature(F)','Wind_Speed(mph)','Precipitation(in)']\n",
    "X = df_train.drop(columns=['Severity']) \n",
    "# predicting severity of an accident at this location with current weather conditions\n",
    "y = df_train['Severity'] \n",
    "\n",
    "# make training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=30, stratify=y)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.4, random_state=30, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6ab8be1-b726-49ec-9328-b0ce4b852276",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature(F)</th>\n",
       "      <th>Wind_Speed(mph)</th>\n",
       "      <th>Precipitation(in)</th>\n",
       "      <th>Rounded_Lat</th>\n",
       "      <th>Rounded_Lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6524059</th>\n",
       "      <td>51.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.03</td>\n",
       "      <td>-118.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3652748</th>\n",
       "      <td>53.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.06</td>\n",
       "      <td>34.00</td>\n",
       "      <td>-117.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3891144</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>34.03</td>\n",
       "      <td>-118.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3841706</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.99</td>\n",
       "      <td>-117.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5480530</th>\n",
       "      <td>57.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>33.97</td>\n",
       "      <td>-118.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Temperature(F)  Wind_Speed(mph)  Precipitation(in)  Rounded_Lat  \\\n",
       "6524059            51.0              3.0               0.00        34.03   \n",
       "3652748            53.0              7.0               0.06        34.00   \n",
       "3891144            66.0              0.0               0.00        34.03   \n",
       "3841706            88.0              0.0               0.00        33.99   \n",
       "5480530            57.0              5.0               0.00        33.97   \n",
       "\n",
       "         Rounded_Lng  \n",
       "6524059      -118.43  \n",
       "3652748      -117.94  \n",
       "3891144      -118.42  \n",
       "3841706      -117.91  \n",
       "5480530      -118.25  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect predictors\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04e3562d-f107-48d4-a947-1b77b71c0b28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 4]\n"
     ]
    }
   ],
   "source": [
    "# check y_values (severity labels) are in range [0,4] not negative or other\n",
    "y_values = y_test.unique()\n",
    "print(y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e30cc853-58ba-41d5-ae18-26183bb8d99f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_train = y_train - 1\n",
    "y_valid = y_valid - 1  \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train_scaled, y_train))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid_scaled, y_valid))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "valid_dataset = valid_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28a103f7-083c-4938-94ac-6199cd3efbf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 4 1]\n"
     ]
    }
   ],
   "source": [
    "unique_values = train['Severity'].unique()\n",
    "print(unique_values) # 4 unique class for accident severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48e07f95-c70e-4a76-b39f-fe7a11969abf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">132</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m132\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">46,820</span> (182.89 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m46,820\u001b[0m (182.89 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,860</span> (179.14 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m45,860\u001b[0m (179.14 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">960</span> (3.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m960\u001b[0m (3.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape = (X_train_scaled.shape[1],)))\n",
    "model.add(Dense(256, activation='relu')) \n",
    "model.add(BatchNormalization()) \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(4, activation='softmax'))  # 4 unique classes for accident severity\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad20bf72-7930-4655-8f42-837d29a883da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m480/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5924 - loss: 1.0781\n",
      "Epoch 1: val_loss improved from inf to 0.04622, saving model to best_model.keras\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.5997 - loss: 1.0614 - val_accuracy: 0.9964 - val_loss: 0.0462 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m491/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9951 - loss: 0.0547\n",
      "Epoch 2: val_loss improved from 0.04622 to 0.02873, saving model to best_model.keras\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9951 - loss: 0.0546 - val_accuracy: 0.9964 - val_loss: 0.0287 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m478/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0364\n",
      "Epoch 3: val_loss improved from 0.02873 to 0.02729, saving model to best_model.keras\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0363 - val_accuracy: 0.9964 - val_loss: 0.0273 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m488/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0331\n",
      "Epoch 4: val_loss improved from 0.02729 to 0.02610, saving model to best_model.keras\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0331 - val_accuracy: 0.9964 - val_loss: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m480/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0289\n",
      "Epoch 5: val_loss did not improve from 0.02610\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0289 - val_accuracy: 0.9964 - val_loss: 0.0262 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m481/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0293\n",
      "Epoch 6: val_loss did not improve from 0.02610\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0292 - val_accuracy: 0.9964 - val_loss: 0.0261 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m490/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0292\n",
      "Epoch 7: val_loss improved from 0.02610 to 0.02533, saving model to best_model.keras\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0292 - val_accuracy: 0.9964 - val_loss: 0.0253 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m493/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0281\n",
      "Epoch 8: val_loss improved from 0.02533 to 0.02518, saving model to best_model.keras\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0281 - val_accuracy: 0.9964 - val_loss: 0.0252 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m492/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0260\n",
      "Epoch 9: val_loss improved from 0.02518 to 0.02438, saving model to best_model.keras\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0260 - val_accuracy: 0.9964 - val_loss: 0.0244 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m481/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0259\n",
      "Epoch 10: val_loss did not improve from 0.02438\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0259 - val_accuracy: 0.9964 - val_loss: 0.0247 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m492/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0265\n",
      "Epoch 11: val_loss did not improve from 0.02438\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0265 - val_accuracy: 0.9964 - val_loss: 0.0250 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m489/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0261\n",
      "Epoch 12: val_loss did not improve from 0.02438\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0260 - val_accuracy: 0.9964 - val_loss: 0.0250 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m476/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0251\n",
      "Epoch 13: val_loss did not improve from 0.02438\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.9963 - loss: 0.0251 - val_accuracy: 0.9964 - val_loss: 0.0257 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m492/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0251\n",
      "Epoch 14: val_loss did not improve from 0.02438\n",
      "\u001b[1m495/495\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.0251 - val_accuracy: 0.9964 - val_loss: 0.0260 - learning_rate: 5.0000e-04\n",
      "Epoch 14: early stopping\n",
      "Restoring model weights from the end of the best epoch: 9.\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    initial_lr = 0.001\n",
    "    drop = 0.5\n",
    "    epochs_drop = 10\n",
    "    lr = initial_lr * (drop ** np.floor((1+epoch)/epochs_drop))\n",
    "    return lr\n",
    "\n",
    "# create checkpoint to save best model during training\n",
    "checkpoint_path = 'best_model.keras'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=50,\n",
    "                    validation_data=valid_dataset,\n",
    "                    callbacks=[checkpoint, early_stopping, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f493a75-abe7-40ff-82ec-a1847ec20e26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile('best_model.keras') # make sure true before loading saved models in later cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "846333cf-e4b0-48a4-91ab-57611902f486",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m75/75\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9967 - loss: 0.0215\n",
      "Validation Accuracy: 0.9964195489883423\n"
     ]
    }
   ],
   "source": [
    "saved_model = tf.keras.models.load_model(\"best_model.keras\")\n",
    "val_loss, val_accuracy = saved_model.evaluate(valid_dataset) \n",
    "print(f\"Validation Accuracy: {val_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3908791-e760-44e6-a469-b394bf096eb0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_test = y_test - 1\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test_scaled, y_test)) \n",
    "test_dataset = test_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbe44a4b-1b5d-476a-bc51-8baba132315d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9959 - loss: 0.0249\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = saved_model.evaluate(test_dataset) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf60dd1f-464d-4af4-88e3-759cdaf55b40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      3155\n",
      "           3       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           1.00      3166\n",
      "   macro avg       0.50      0.50      0.50      3166\n",
      "weighted avg       0.99      1.00      0.99      3166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\littl\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\littl\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\littl\\anaconda3\\envs\\PIC16B-25W\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "y_pred = np.argmax(saved_model.predict(X_test_scaled), axis=1) \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "138cf24b-9fa7-4caa-9e3e-a0186d025370",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Weather Data for Latitude 34.05, Longitude -118.25\n",
      "\n",
      "\n",
      " Weather Data for Latitude 34.05, Longitude -118.25\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Snow_Precipitation</th>\n",
       "      <th>Dew_Point_2m</th>\n",
       "      <th>Total_Precipitation_mm</th>\n",
       "      <th>Temperature_2m_C</th>\n",
       "      <th>Wind_Speed_2m</th>\n",
       "      <th>Rounded_Lat</th>\n",
       "      <th>Rounded_Lng</th>\n",
       "      <th>Precipitation(in)</th>\n",
       "      <th>Temperature(F)</th>\n",
       "      <th>Wind_Speed(mph)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.04</td>\n",
       "      <td>12.14</td>\n",
       "      <td>1.64</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>53.852</td>\n",
       "      <td>3.66868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>11.55</td>\n",
       "      <td>1.59</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>52.790</td>\n",
       "      <td>3.55683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.75</td>\n",
       "      <td>5.87</td>\n",
       "      <td>10.86</td>\n",
       "      <td>3.25</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.231102</td>\n",
       "      <td>51.548</td>\n",
       "      <td>7.27025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>0.02</td>\n",
       "      <td>9.76</td>\n",
       "      <td>2.89</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>49.568</td>\n",
       "      <td>6.46493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.99</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10.80</td>\n",
       "      <td>2.00</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.440</td>\n",
       "      <td>4.47400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-01-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.12</td>\n",
       "      <td>10.50</td>\n",
       "      <td>2.86</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.004724</td>\n",
       "      <td>50.900</td>\n",
       "      <td>6.39782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024-01-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.26</td>\n",
       "      <td>7.77</td>\n",
       "      <td>5.29</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "      <td>0.010236</td>\n",
       "      <td>45.986</td>\n",
       "      <td>11.83373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  Snow_Precipitation  Dew_Point_2m  Total_Precipitation_mm  \\\n",
       "0 2024-01-01                 0.0          6.12                    0.04   \n",
       "1 2024-01-02                 0.0          7.05                    0.09   \n",
       "2 2024-01-03                 0.0          6.75                    5.87   \n",
       "3 2024-01-04                 0.0          2.14                    0.02   \n",
       "4 2024-01-05                 0.0          1.99                    0.00   \n",
       "5 2024-01-06                 0.0          1.23                    0.12   \n",
       "6 2024-01-07                 0.0         -0.09                    0.26   \n",
       "\n",
       "   Temperature_2m_C  Wind_Speed_2m  Rounded_Lat  Rounded_Lng  \\\n",
       "0             12.14           1.64        34.05      -118.25   \n",
       "1             11.55           1.59        34.05      -118.25   \n",
       "2             10.86           3.25        34.05      -118.25   \n",
       "3              9.76           2.89        34.05      -118.25   \n",
       "4             10.80           2.00        34.05      -118.25   \n",
       "5             10.50           2.86        34.05      -118.25   \n",
       "6              7.77           5.29        34.05      -118.25   \n",
       "\n",
       "   Precipitation(in)  Temperature(F)  Wind_Speed(mph)  \n",
       "0           0.001575          53.852          3.66868  \n",
       "1           0.003543          52.790          3.55683  \n",
       "2           0.231102          51.548          7.27025  \n",
       "3           0.000787          49.568          6.46493  \n",
       "4           0.000000          51.440          4.47400  \n",
       "5           0.004724          50.900          6.39782  \n",
       "6           0.010236          45.986         11.83373  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature(F)</th>\n",
       "      <th>Wind_Speed(mph)</th>\n",
       "      <th>Precipitation(in)</th>\n",
       "      <th>Rounded_Lat</th>\n",
       "      <th>Rounded_Lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53.852</td>\n",
       "      <td>3.66868</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.790</td>\n",
       "      <td>3.55683</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51.548</td>\n",
       "      <td>7.27025</td>\n",
       "      <td>0.231102</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.568</td>\n",
       "      <td>6.46493</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.440</td>\n",
       "      <td>4.47400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34.05</td>\n",
       "      <td>-118.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature(F)  Wind_Speed(mph)  Precipitation(in)  Rounded_Lat  \\\n",
       "0          53.852          3.66868           0.001575        34.05   \n",
       "1          52.790          3.55683           0.003543        34.05   \n",
       "2          51.548          7.27025           0.231102        34.05   \n",
       "3          49.568          6.46493           0.000787        34.05   \n",
       "4          51.440          4.47400           0.000000        34.05   \n",
       "\n",
       "   Rounded_Lng  \n",
       "0      -118.25  \n",
       "1      -118.25  \n",
       "2      -118.25  \n",
       "3      -118.25  \n",
       "4      -118.25  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = get_nasa_power_data(34.05, -118.25, \"20240101\", \"20240107\")\n",
    "df = df_test[['Temperature(F)','Wind_Speed(mph)','Precipitation(in)','Rounded_Lat','Rounded_Lng']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b46afe86-b4b0-4fbd-9f1d-578e028ed73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
      "[1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "nasa_test = scaler.transform(df)\n",
    "test = np.argmax(saved_model.predict(nasa_test), axis=1)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a30b14e4-bb8a-4508-b172-2251e38ddd8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '[' (2351906007.py, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[39], line 15\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(f\"    - Temperature (F): {nasa_data[\"Temperature(F)\"]}\")\u001b[0m\n\u001b[1;37m                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string: unmatched '['\n"
     ]
    }
   ],
   "source": [
    "def estimate_severity(latitude, longitude, current_time):\n",
    "    \"\"\" \n",
    "    Args:\n",
    "        - latitude, double coordinate from map\n",
    "        - longitude, double coordinate from map\n",
    "        - current_time, str representing current date Pacific Standard Time\n",
    "    Return: \n",
    "        - none, prints severity estimate\n",
    "    \"\"\"\n",
    "    nasa_data = get_nasa_power_date(latitude, longitude, current_time)\n",
    "    nasa_scaled = scaler.transform(df)\n",
    "    saved_model = tf.keras.models.load_model(\"best_model.keras\")\n",
    "    severity = np.argmax(saved_model.predict(nasa_scaled), axis=1)\n",
    "    print(f\"The current weather is: \")\n",
    "    print(f\"    - Temperature (F): {nasa_data[\"Temperature(F)\"]}\")\n",
    "    print(f\"    - Wind Speed (mph): {nasa_data[\"Wind_Speed(mph)\"]}\")\n",
    "    print(f\"    - Precipitation (in): {nasa_data[\"Precipitation(in)\"]}\")\n",
    "    print(f\"The estimated accident severity for this location and weather conditions is: {severity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "721583eb-9de1-47d8-9a0e-dc0623da1816",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# add in necessary libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from plotly import express as px\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from dash import Dash, dcc, html, dash_table, Input, Output, State, callback, no_update\n",
    "\n",
    "import base64\n",
    "import datetime\n",
    "from datetime import date, datetime\n",
    "import io\n",
    "import pytz\n",
    "from pytz import timezone\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.io as pio\n",
    "from plotly import express as px\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "import dash_bootstrap_components as dbc\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f813000f-42bb-4316-9379-8d158015411b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:1010/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1bbe60a7b10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dash import Dash, html, Input, Output, Patch\n",
    "import dash_leaflet as dl\n",
    "import json\n",
    "\n",
    "\n",
    "app = Dash()\n",
    "app.layout = html.Div([\n",
    "    \n",
    "    dcc.Markdown('''\n",
    "        ## Directions: \n",
    "        Pan and zoom in/out on the map to find your location.\n",
    "        Click your location on the map for current weather risk estimation.\n",
    "        Your risk estimates will load promptly.'''),\n",
    "\n",
    "    \n",
    "    dcc.Markdown('''## Select Location:'''),\n",
    "\n",
    "    dl.Map(\n",
    "        id='map',\n",
    "        children=[\n",
    "            dl.TileLayer()\n",
    "        ],\n",
    "        center=[34, -118],\n",
    "        zoom=9,\n",
    "        style={'height': '50vh'}\n",
    "    ),\n",
    "    html.Div(id='out')\n",
    "    ]\n",
    ")\n",
    "    \n",
    "\n",
    "\n",
    "@app.callback(\n",
    "    Output('out', 'children'),\n",
    "    Output('map', 'children'),\n",
    "    Input('map', 'clickData'),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def map(click_data):\n",
    "    # extract coordinates form click_data\n",
    "    coordinates = click_data['latlng']\n",
    "    latitude, longitude = coordinates.values()\n",
    "    current_date = date.today().strftime('%Y%m%d')\n",
    "    estimate_severity(latitude, longitude, current_date)\n",
    "\n",
    "    # create Patch() instance, add Marker layer at click coordinates\n",
    "    patched = Patch()\n",
    "    patched.append(dl.Marker(position=[latitude, longitude]))\n",
    "\n",
    "    return json.dumps(coordinates), patched\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=1010,debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "262ff984-a8d3-4ccc-91a6-643caf7e6a00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'le' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mle\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'le' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757bae75-13a0-4005-8126-fe59e6ab40a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PIC16B-25W] *",
   "language": "python",
   "name": "conda-env-PIC16B-25W-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
